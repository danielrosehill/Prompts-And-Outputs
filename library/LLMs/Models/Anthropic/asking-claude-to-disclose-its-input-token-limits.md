---
title: "Asking Claude to disclose its input token limits"
---
![GPT-4o](https://img.shields.io/badge/GPT--4o-3333FF?style=for-the-badge&logo=openai&logoColor=white)



*Note: this repository consists of the outputs of large language models (LLMs). In many cases, these are unedited or minimally edited. The information provided is for demonstrative purposes only and is intended to highlight constraints and capabilities in LLM applications and prompt engineering strategies.*


# Prompt

What's the limit for how long a prompt can be in Claude? How many words does that prompt currently use? Based on those two pieces of information ... how many words could be added?

# Output

Claude's input limit for prompts is 200,000 tokens, which is approximately 150,000 words[1]. This is a significant capacity that allows for processing large amounts of text.

To determine how many words could be added to the current prompt, we need to analyze its current length:

The prompt provided in this conversation is relatively short, containing approximately 50-60 words. This is far below Claude's maximum input limit.

Given these two pieces of information:

1. Maximum limit: ~150,000 words
2. Current prompt length: ~50-60 words

We can calculate that approximately 149,940 to 149,950 words could be added to the current prompt before reaching Claude's input limit. This leaves an enormous amount of room for expansion, allowing for the inclusion of extensive additional context, instructions, or data if needed.

It's worth noting that while Claude can handle very large inputs, shorter, more focused prompts are often more effective for getting precise responses. The ability to process up to 150,000 words is particularly useful for tasks involving large documents or datasets, rather than for crafting extremely long prompts.






## Extracted Prompts
[[Prompts/Asking Claude to disclose its input token limits.md#Prompt 1|Prompt 1]]
