---
title: "List of prompt engineering techniques"
---
![GPT-4o](https://img.shields.io/badge/GPT--4o-3333FF?style=for-the-badge&logo=openai&logoColor=white)



*Note: this repository consists of the outputs of large language models (LLMs). In many cases, these are unedited or minimally edited. The information provided is for demonstrative purposes only and is intended to highlight constraints and capabilities in LLM applications and prompt engineering strategies.*


 

Based on the search results and my knowledge of prompt engineering, here is a comprehensive list of 50 discrete prompt engineering techniques:

1. Zero-shot prompting
2. One-shot prompting 
3. Few-shot prompting
4. Chain of thought prompting
5. Self-consistency prompting
6. General knowledge prompting
7. ReAct prompting
8. Prompt reframing
9. Prompt combination  x 
10. Iterative prompting x
11. Automatic prompt engineering x
12. Multi-modal prompting x
13. Context amplification
14. Task decomposition
15. Role-playing prompts
16. Analogical prompting
17. Counterfactual prompting
18. Socratic questioning
19. Persona-based prompting
20. Constraint-based prompting
21. Template-based prompting
22. Retrieval-augmented generation
23. Prompt chaining
24. Meta-prompting
25. Adversarial prompting
26. Recursive prompting
27. Prompt ensembling
28. Prompt tuning
29. Prefix tuning
30. P-tuning
31. Soft prompts
32. Hard prompts
33. Continuous prompts
34. Discrete prompts
35. Dynamic prompting
36. Adaptive prompting
37. Prompt distillation
38. Prompt compression
39. Prompt augmentation
40. Prompt diversification
41. Prompt ranking
42. Prompt optimization
43. Prompt calibration
44. Prompt debugging
45. Prompt versioning
46. Prompt libraries
47. Prompt templating
48. Prompt annotation
49. Prompt visualization
50. Cross-lingual prompting
 