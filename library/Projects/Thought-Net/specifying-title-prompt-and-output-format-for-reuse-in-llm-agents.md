---
title: "Specifying title prompt and output format for reuse in LLM agents"
---
![GPT-4o](https://img.shields.io/badge/GPT--4o-3333FF?style=for-the-badge&logo=openai&logoColor=white)



*Note: this repository consists of the outputs of large language models (LLMs). In many cases, these are unedited or minimally edited. The information provided is for demonstrative purposes only and is intended to highlight constraints and capabilities in LLM applications and prompt engineering strategies.*


# Prompt

I'd like to create a ChatGPT agent which structures its output in a very specific format (for me to record in a note manager)

The format would be like this (my descriptions are in brackets)

# Title (a one line summary of what the output is about)

# Prompt (a summarised version of what the user prompted)

{prompt text}

# Output

{output text}

How could I specify this as an instruction for a custom agent?

# Output


To create a custom **ChatGPT agent** that structures its output in the specific format you described, you can provide it with clear instructions. Here's how you could specify the format as part of the agent's guidelines:

### Instructions for the Agent:

1. **Title**: Begin with a one-line summary of the output content.
   - Format: `# Title`
   - Example: `# Summary of Cloudflare Tunnel Configuration`

2. **Prompt**: Provide a summarized version of the user’s prompt.
   - Format: `# Prompt`
   - Example: `# Prompt`
   - Content: `{prompt text}` (Replace with a brief version of the user's input.)

3. **Output**: Provide the actual output in response to the prompt.
   - Format: `# Output`
   - Example: `# Output`
   - Content: `{output text}` (Insert the generated content or result.)

### Example:

Here’s how you can express the instructions as part of the configuration or development for your custom agent:

```plaintext
1. Start with a "Title" section: Provide a one-line summary of what the output is about, formatted as `# Title`.
2. Add a "Prompt" section: Summarize the user’s prompt as a summary, formatted as `# Prompt`.
3. Add an "Output" section: Place the generated response under `# Output`.
4. Ensure each section is clearly separated and uses the exact header formats (`# Title`, `# Prompt`, `# Output`).
```

### Example Use Case:

#### Input (for the custom agent):
```
User Prompt: How do I set up a reverse proxy for my home server using NGINX?
```

#### Output from the Agent:
```plaintext
# Title
Reverse Proxy Setup with NGINX for Home Server

# Prompt
How to set up a reverse proxy for a home server using NGINX.

# Output
1. Install NGINX:
   ```bash
   sudo apt install nginx
   ```

2. Configure the reverse proxy by editing `/etc/nginx/sites-available/default`:
   ```bash
   server {
       listen 80;
       server_name example.com;
       location / {
           proxy_pass http://127.0.0.1:8080;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
       }
   }
   ```

3. Restart NGINX:
   ```bash
   sudo systemctl restart nginx
   ```
```

This structured format would be followed for every response generated by the custom ChatGPT agent.

Let me know if you'd like further customization!